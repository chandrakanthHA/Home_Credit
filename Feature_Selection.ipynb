{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Home_Loan/application_train.csv.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "def clean_data(df, test=True):\n",
    "    global mm_scaler, std_scaler\n",
    "    \n",
    "    # Drop rows where target value is missing\n",
    "    df.dropna(subset=[\"TARGET\"], inplace=True)\n",
    "    \n",
    "    # Drop rows where important monetary values are missing\n",
    "    df.dropna(subset=[\"AMT_INCOME_TOTAL\", \"AMT_CREDIT\",\n",
    "                      \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\"],\n",
    "              inplace=True)\n",
    "    \n",
    "    # Drop outliers\n",
    "    if not test:\n",
    "        idx = np.all(stats.zscore(df[[\"AMT_INCOME_TOTAL\", \"AMT_CREDIT\",\n",
    "                                      \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\"]]) < 3, axis=1)\n",
    "        df = df[idx]\n",
    "    \n",
    "    # Drop outlier from \"DAYS_EMPLOYED\" and the \"SOCIAL_CIRCLE\" columns\n",
    "    df.drop(index=df[df[\"DAYS_EMPLOYED\"] >= 50000].index, inplace=True)\n",
    "    df.drop(index=df[df[\"OBS_30_CNT_SOCIAL_CIRCLE\"] >= 100].index, inplace=True)\n",
    "    df.drop(index=df[df[\"DEF_30_CNT_SOCIAL_CIRCLE\"] >= 100].index, inplace=True)\n",
    "    df.drop(index=df[df[\"OBS_60_CNT_SOCIAL_CIRCLE\"] >= 100].index, inplace=True)\n",
    "    df.drop(index=df[df[\"DEF_60_CNT_SOCIAL_CIRCLE\"] >= 100].index, inplace=True)\n",
    "    \n",
    "    # Create list y with target values\n",
    "    y = df[\"TARGET\"].astype(\"int\").astype(\"category\")\n",
    "    \n",
    "    # Create DataFrame X for all features\n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    # Copy already correct columns\n",
    "    X[\"REGION_POPULATION_RELATIVE\"] = df[\"REGION_POPULATION_RELATIVE\"]\n",
    "    \n",
    "    # Convert data types\n",
    "    X[\"FLAG_OWN_CAR\"] = df[\"FLAG_OWN_CAR\"].replace([\"Y\", \"N\"], [1, 0]).astype(\"int\")\n",
    "    X[\"FLAG_OWN_REALTY\"] = df[\"FLAG_OWN_REALTY\"].replace([\"Y\", \"N\"], [1, 0]).astype(\"int\")\n",
    "    X[\"REG_REGION_NOT_LIVE_REGION\"] = df[\"REG_REGION_NOT_LIVE_REGION\"].astype(\"int\")\n",
    "    X[\"REG_REGION_NOT_WORK_REGION\"] = df[\"REG_REGION_NOT_WORK_REGION\"].astype(\"int\")\n",
    "    X[\"LIVE_REGION_NOT_WORK_REGION\"] = df[\"LIVE_REGION_NOT_WORK_REGION\"].astype(\"int\")\n",
    "    X[\"REG_CITY_NOT_LIVE_CITY\"] = df[\"REG_CITY_NOT_LIVE_CITY\"].astype(\"int\")\n",
    "    X[\"REG_CITY_NOT_WORK_CITY\"] = df[\"REG_CITY_NOT_WORK_CITY\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_2\"] = df[\"FLAG_DOCUMENT_2\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_3\"] = df[\"FLAG_DOCUMENT_3\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_4\"] = df[\"FLAG_DOCUMENT_4\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_5\"] = df[\"FLAG_DOCUMENT_5\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_6\"] = df[\"FLAG_DOCUMENT_6\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_7\"] = df[\"FLAG_DOCUMENT_7\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_8\"] = df[\"FLAG_DOCUMENT_8\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_9\"] = df[\"FLAG_DOCUMENT_9\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_10\"] = df[\"FLAG_DOCUMENT_10\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_11\"] = df[\"FLAG_DOCUMENT_11\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_12\"] = df[\"FLAG_DOCUMENT_12\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_13\"] = df[\"FLAG_DOCUMENT_13\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_14\"] = df[\"FLAG_DOCUMENT_14\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_15\"] = df[\"FLAG_DOCUMENT_15\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_16\"] = df[\"FLAG_DOCUMENT_16\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_17\"] = df[\"FLAG_DOCUMENT_17\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_18\"] = df[\"FLAG_DOCUMENT_18\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_19\"] = df[\"FLAG_DOCUMENT_19\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_20\"] = df[\"FLAG_DOCUMENT_20\"].astype(\"int\")\n",
    "    X[\"FLAG_DOCUMENT_21\"] = df[\"FLAG_DOCUMENT_21\"].astype(\"int\")\n",
    "    \n",
    "    # Create dummy variables for categorical columns\n",
    "    X = pd.concat([X, pd.get_dummies(df[[\"NAME_CONTRACT_TYPE\", \"CODE_GENDER\", \"NAME_TYPE_SUITE\",\n",
    "                                         \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"NAME_FAMILY_STATUS\",\n",
    "                                         \"NAME_HOUSING_TYPE\", \"ORGANIZATION_TYPE\"]],\n",
    "                                     drop_first=True)], 1)\n",
    "    \n",
    "    # Filling all NaNs with mean values\n",
    "    col_names = df.loc[:, \"EXT_SOURCE_1\" : \"NONLIVINGAREA_MEDI\"].columns\n",
    "    X[col_names] = df[col_names].fillna(value=df[col_names].median())\n",
    "    X[\"TOTALAREA_MODE\"] = df[\"TOTALAREA_MODE\"].fillna(value=df[\"TOTALAREA_MODE\"].median())\n",
    "    \n",
    "    social_circle = [\"OBS_30_CNT_SOCIAL_CIRCLE\", \"DEF_30_CNT_SOCIAL_CIRCLE\",\n",
    "                     \"OBS_60_CNT_SOCIAL_CIRCLE\", \"DEF_60_CNT_SOCIAL_CIRCLE\"]\n",
    "    X[social_circle] = df[social_circle].fillna(value=df[social_circle].median())\n",
    "    \n",
    "    enquiries = [\"AMT_REQ_CREDIT_BUREAU_HOUR\", \"AMT_REQ_CREDIT_BUREAU_DAY\",\n",
    "                 \"AMT_REQ_CREDIT_BUREAU_WEEK\", \"AMT_REQ_CREDIT_BUREAU_MON\",\n",
    "                 \"AMT_REQ_CREDIT_BUREAU_QRT\", \"AMT_REQ_CREDIT_BUREAU_YEAR\"]\n",
    "    X[enquiries] = df[enquiries].fillna(value=df[enquiries].median())    \n",
    "    \n",
    "    # Use Scaler\n",
    "    std_scaled = [\"AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \"AMT_ANNUITY\",\n",
    "                  \"AMT_GOODS_PRICE\", \"REGION_RATING_CLIENT_W_CITY\"]\n",
    "    mm_scaled = [\"DAYS_BIRTH\", \"DAYS_EMPLOYED\",\n",
    "                 \"DAYS_REGISTRATION\", \"DAYS_ID_PUBLISH\"]\n",
    "    if test:\n",
    "        X[[\"CNT_CHILDREN\"]] = mm_scaler.transform(df[[\"CNT_CHILDREN\"]])\n",
    "        X[std_scaled] = std_scaler.transform(df[std_scaled])\n",
    "        X[mm_scaled] = mm_scaler.transform(df[mm_scaled] * -1)\n",
    "        X[social_circle] = mm_scaler.transform(X[social_circle])\n",
    "        X[enquiries] = mm_scaler.transform(X[enquiries])\n",
    "    else:\n",
    "        X[[\"CNT_CHILDREN\"]] = mm_scaler.fit_transform(df[[\"CNT_CHILDREN\"]])\n",
    "        X[std_scaled] = std_scaler.fit_transform(df[std_scaled])\n",
    "        X[mm_scaled] = mm_scaler.fit_transform(df[mm_scaled] * -1)\n",
    "        X[social_circle] = mm_scaler.fit_transform(X[social_circle])\n",
    "        X[enquiries] = mm_scaler.fit_transform(X[enquiries])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = clean_data(df, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 178 out of 178 | elapsed:    9.8s finished\n",
      "\n",
      "[2020-11-03 14:28:21] Features: 1/20 -- score: 0.9426645622655938[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done 177 out of 177 | elapsed:   53.8s finished\n",
      "\n",
      "[2020-11-03 14:29:15] Features: 2/20 -- score: 0.9999552543586322[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:  1.1min finished\n",
      "\n",
      "[2020-11-03 14:30:22] Features: 3/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 175 out of 175 | elapsed:  1.2min finished\n",
      "\n",
      "[2020-11-03 14:31:35] Features: 4/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 174 out of 174 | elapsed:  1.3min finished\n",
      "\n",
      "[2020-11-03 14:32:52] Features: 5/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 out of 173 | elapsed:  1.3min finished\n",
      "\n",
      "[2020-11-03 14:34:12] Features: 6/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 172 out of 172 | elapsed:  1.3min finished\n",
      "\n",
      "[2020-11-03 14:35:30] Features: 7/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 171 out of 171 | elapsed:  1.3min finished\n",
      "\n",
      "[2020-11-03 14:36:51] Features: 8/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 170 out of 170 | elapsed:  1.4min finished\n",
      "\n",
      "[2020-11-03 14:38:14] Features: 9/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 169 out of 169 | elapsed:  1.4min finished\n",
      "\n",
      "[2020-11-03 14:39:38] Features: 10/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed:  1.4min finished\n",
      "\n",
      "[2020-11-03 14:41:03] Features: 11/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 167 out of 167 | elapsed:  1.4min finished\n",
      "\n",
      "[2020-11-03 14:42:27] Features: 12/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 166 out of 166 | elapsed:  1.4min finished\n",
      "\n",
      "[2020-11-03 14:43:53] Features: 13/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 165 out of 165 | elapsed:  1.4min finished\n",
      "\n",
      "[2020-11-03 14:45:19] Features: 14/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 164 out of 164 | elapsed:  1.5min finished\n",
      "\n",
      "[2020-11-03 14:46:46] Features: 15/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 163 out of 163 | elapsed:  1.5min finished\n",
      "\n",
      "[2020-11-03 14:48:14] Features: 16/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:  1.6min finished\n",
      "\n",
      "[2020-11-03 14:49:51] Features: 17/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:  1.5min finished\n",
      "\n",
      "[2020-11-03 14:51:24] Features: 18/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.5min finished\n",
      "\n",
      "[2020-11-03 14:52:56] Features: 19/20 -- score: 1.0[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 159 out of 159 | elapsed:  1.5min finished\n",
      "\n",
      "[2020-11-03 14:54:27] Features: 20/20 -- score: 1.0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('REGION_POPULATION_RELATIVE',\n",
       " 'FLAG_OWN_CAR',\n",
       " 'FLAG_OWN_REALTY',\n",
       " 'REG_REGION_NOT_LIVE_REGION',\n",
       " 'REG_REGION_NOT_WORK_REGION',\n",
       " 'LIVE_REGION_NOT_WORK_REGION',\n",
       " 'REG_CITY_NOT_LIVE_CITY',\n",
       " 'REG_CITY_NOT_WORK_CITY',\n",
       " 'FLAG_DOCUMENT_2',\n",
       " 'FLAG_DOCUMENT_3',\n",
       " 'FLAG_DOCUMENT_4',\n",
       " 'FLAG_DOCUMENT_5',\n",
       " 'FLAG_DOCUMENT_6',\n",
       " 'FLAG_DOCUMENT_7',\n",
       " 'FLAG_DOCUMENT_8',\n",
       " 'FLAG_DOCUMENT_9',\n",
       " 'FLAG_DOCUMENT_10',\n",
       " 'EXT_SOURCE_2',\n",
       " 'AMT_INCOME_TOTAL',\n",
       " 'DAYS_BIRTH')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential Forward Floating Selection (sffs)\n",
    "sffs = SFS(DecisionTreeClassifier(),\n",
    "           k_features=(20),\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           cv=0,\n",
    "           n_jobs=-1)\n",
    "\n",
    "sffs.fit(X, y)\n",
    "\n",
    "sffs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 features: ['REGION_POPULATION_RELATIVE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'EXT_SOURCE_2', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
